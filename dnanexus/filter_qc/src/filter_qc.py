#!/usr/bin/env python
# filter_qc 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# See https://wiki.dnanexus.com/Developer-Portal for documentation and
# tutorials on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import os
import subprocess
import shlex
import time
import re
from multiprocessing import Pool, cpu_count
import dxpy
import common

logger = logging.getLogger(__name__)


def dup_parse(fname):
    with open(fname, 'r') as dup_file:
        if not dup_file:
            return None

        lines = iter(dup_file.read().splitlines())

        for line in lines:
            if line.startswith('## METRICS CLASS'):
                headers = lines.next().rstrip('\n').lower()
                metrics = lines.next().rstrip('\n')
                break

        headers = headers.split('\t')
        metrics = metrics.split('\t')
        headers.pop(0)
        metrics.pop(0)

        dup_qc = dict(zip(headers, metrics))
    return dup_qc


def pbc_parse(fname):
    with open(fname, 'r') as pbc_file:
        if not pbc_file:
            return None

        lines = pbc_file.read().splitlines()
        line = lines[0].rstrip('\n')
        # PBC File output:
        #   TotalReadPairs <tab>
        #   DistinctReadPairs <tab>
        #   OneReadPair <tab>
        #   TwoReadPairs <tab>
        #   NRF=Distinct/Total <tab>
        #   PBC1=OnePair/Distinct <tab>
        #   PBC2=OnePair/TwoPair

        headers = ['TotalReadPairs',
                   'DistinctReadPairs',
                   'OneReadPair',
                   'TwoReadPairs',
                   'NRF',
                   'PBC1',
                   'PBC2']
        metrics = line.split('\t')

        pbc_qc = dict(zip(headers, metrics))
    return pbc_qc


@dxpy.entry_point('main')
def main(input_bam, paired_end, samtools_params, debug, skip_filter):

    if debug:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.INFO)

    input_bam_file = dxpy.DXFile(input_bam)

    input_bam_filename = input_bam_file.name
    m = re.search('(.*)\.bam$', input_bam_filename)
    if m:
        input_bam_basename = m.group(1)
    else:
        input_bam_basename = input_bam_filename
    dxpy.download_dxfile(input_bam_file.get_id(), input_bam_filename)

    subprocess.check_output('ls -l', shell=True)

    if not skip_filter:
        filt_bam_prefix = input_bam_basename + ".filt.srt"
        filt_bam_filename = filt_bam_prefix + ".bam"
        if paired_end:
            # =============================
            # Remove  unmapped, mate unmapped
            # not primary alignment, reads failing platform
            # Remove low MAPQ reads
            # Only keep properly paired reads
            # Obtain name sorted BAM file
            # ==================
            tmp_filt_bam_prefix = "tmp.%s" %(filt_bam_prefix) #was tmp.prefix.nmsrt
            tmp_filt_bam_filename = tmp_filt_bam_prefix + ".bam"
            out,err = common.run_pipe([
                #filter:  -F 1804 FlAG bits to exclude; -f 2 FLAG bits to reqire; -q 30 exclude MAPQ < 30; -u uncompressed output
                #exclude FLAG 1804: unmapped, next segment unmapped, secondary alignments, not passing platform q, PCR or optical duplicates
                #require FLAG 2: properly aligned
                "samtools view -F 1804 -f 2 %s -u %s" %(samtools_params, input_bam_filename),
                #sort:  -n sort by name; - take input from stdin; out to specified filename
                "samtools sort -n - %s" %(tmp_filt_bam_prefix)])  # Will produce name sorted BAM
            if err:
                logger.error("samtools error: %s" %(err))
            # Remove orphan reads (pair was removed)
            # and read pairs mapping to different chromosomes
            # Obtain position sorted BAM
            print subprocess.check_output('ls -l', shell=True)
            out,err = common.run_pipe([
                #fill in mate coordinates, ISIZE and mate-related flags
                #fixmate requires name-sorted alignment; -r removes secondary and unmapped (redundant here because already done above?)
                #- send output to stdout
                "samtools fixmate -r %s -" %(tmp_filt_bam_filename),
                #repeat filtering after mate repair
                "samtools view -F 1804 -f 2 -u -",
                #produce the coordinate-sorted BAM
                "samtools sort - %s" %(filt_bam_prefix)])
            print subprocess.check_output('ls -l', shell=True)
        else: #single-end data
            # =============================
            # Remove unmapped, mate unmapped
            # not primary alignment, reads failing platform
            # Remove low MAPQ reads
            # Obtain name sorted BAM file
            # ==================  
            with open(filt_bam_filename, 'w') as fh:
                subprocess.check_call(shlex.split("samtools view -F 1804 %s -b %s"
                    %(samtools_params, input_bam_filename)), stdout=fh)

        # ========================
        # Mark duplicates
        # ======================
        tmp_filt_bam_filename = input_bam_basename + ".dupmark.bam"
        dup_file_qc_filename = input_bam_basename + ".dup.qc"
        subprocess.check_call(shlex.split(
            "java -Xmx4G -jar /picard/MarkDuplicates.jar INPUT=%s OUTPUT=%s METRICS_FILE=%s \
             VALIDATION_STRINGENCY=LENIENT ASSUME_SORTED=true REMOVE_DUPLICATES=false"
             %(filt_bam_filename, tmp_filt_bam_filename, dup_file_qc_filename)))
        os.rename(tmp_filt_bam_filename,filt_bam_filename)

        if paired_end:
            final_bam_prefix = input_bam_basename + ".filt.srt.nodup"
        else:
            final_bam_prefix = input_bam_basename + ".filt.nodup.srt"
        final_bam_filename = final_bam_prefix + ".bam" # To be stored
        final_bam_index_filename = final_bam_prefix + ".bai" # To be stored

        if paired_end:
            # ============================
            # Remove duplicates
            # Index final position sorted BAM
            # Create final name sorted BAM
            # ============================
            with open(final_bam_filename, 'w') as fh:
                subprocess.check_call(shlex.split("samtools view -F 1804 -f2 -b %s"
                    %(filt_bam_filename)), stdout=fh)
            #namesorting is needed for bam->bedPE, so moved to xcor
            #final_nmsrt_bam_prefix = input_bam_basename + ".filt.nmsrt.nodup"
            #final_nmsrt_bam_filename = final_nmsrt_bam_prefix + ".bam"
            #subprocess.check_call(shlex.split("samtools sort -n %s %s" %(final_bam_filename, final_nmsrt_bam_prefix)))
        else:
            # ============================
            # Remove duplicates
            # Index final position sorted BAM
            # ============================
            with open(final_bam_filename, 'w') as fh:
                subprocess.check_call(shlex.split("samtools view -F 1804 -b %s"
                    %(filt_bam_filename)), stdout=fh)
    else:  # skip_filter
        filt_bam_filename = input_bam_filename
        final_bam_filename = input_bam_filename
        final_bam_prefix = input_bam_basename

    # Index final bam file
    subprocess.check_call(shlex.split(
        "samtools index %s %s"
        % (final_bam_filename, final_bam_index_filename)))

    # Generate mapping statistics
    # QC file
    final_bam_file_mapstats_filename = final_bam_prefix + ".flagstat.qc"
    with open(final_bam_file_mapstats_filename, 'w') as fh:
        subprocess.check_call(shlex.split(
            "samtools flagstat %s"
            % (final_bam_filename)), stdout=fh)

    # =============================
    # Compute library complexity
    # =============================
    # Sort by name
    # convert to bedPE and obtain fragment coordinates
    # sort by position and strand
    # Obtain unique count statistics
    pbc_file_qc_filename = final_bam_prefix + ".pbc.qc"
    # PBC File output
    # TotalReadPairs [tab] DistinctReadPairs [tab] OneReadPair [tab] TwoReadPairs [tab] NRF=Distinct/Total [tab] PBC1=OnePair/Distinct [tab] PBC2=OnePair/TwoPair
    if paired_end:
        steps = [
            "samtools sort -no %s -" % (filt_bam_filename),
            "bamToBed -bedpe -i stdin",
            r"""awk 'BEGIN{OFS="\t"}{print $1,$2,$4,$6,$9,$10}'"""]
    else:
        steps = [
            "bamToBed -i %s" % (filt_bam_filename),
            r"""awk 'BEGIN{OFS="\t"}{print $1,$2,$3,$6}'"""]
    # these st
    steps.extend([
        "grep -v 'chrM'",  # TODO this should be implemented as an explicit list of allowable names, so that mapping can be done to a complete reference
        "sort",
        "uniq -c",
        r"""awk 'BEGIN{mt=0;m0=0;m1=0;m2=0} ($1==1){m1=m1+1} ($1==2){m2=m2+1} {m0=m0+1} {mt=mt+$1} END{printf "%d\t%d\t%d\t%d\t%f\t%f\t%f\n",mt,m0,m1,m2,m0/mt,m1/m0,m1/m2}'"""
        ])
    out, err = common.run_pipe(steps, pbc_file_qc_filename)
    if err:
        print "PBC file error: %s" % (err)

    print "Uploading results files to the project"
    if skip_filter:
        filtered_bam = input_bam
        dup_file = None
        dup_qc = None
    else:
        filtered_bam = dxpy.upload_local_file(final_bam_filename)
        dup_file = dxpy.upload_local_file(dup_file_qc_filename)
        dup_qc = dup_parse(dup_file_qc_filename)

    filtered_bam_index = dxpy.upload_local_file(final_bam_index_filename)
    filtered_mapstats = dxpy.upload_local_file(final_bam_file_mapstats_filename)
    pbc_file = dxpy.upload_local_file(pbc_file_qc_filename)
    pbc_qc = pbc_parse(pbc_file_qc_filename)
    print "dup_qc: %s" % (dup_qc)
    print "pbc_qc: %s" % (pbc_qc)

    # Return links to the output files
    output = {
        "filtered_bam": dxpy.dxlink(filtered_bam),
        "filtered_bam_index": dxpy.dxlink(filtered_bam_index),
        "filtered_mapstats": dxpy.dxlink(filtered_mapstats),
        "pbc_file_qc": dxpy.dxlink(pbc_file),
        "paired_end": paired_end,
        "NRF": pbc_qc.get('NRF'),
        "PBC1": pbc_qc.get('PBC1'),
        "PBC2": pbc_qc.get('PBC2'),
    }
    if not skip_filter:
        output.update({
            "dup_file_qc": dxpy.dxlink(dup_file),
            "duplicate_fraction": dup_qc.get('percent_duplication')
        })
    print "Exiting with output: %s" % (output)
    return output

dxpy.run()
